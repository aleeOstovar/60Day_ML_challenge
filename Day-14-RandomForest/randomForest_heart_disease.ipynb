{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline_model(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Train and evaluate a baseline Random Forest model.\"\"\"\n",
    "    baseline_rf = RandomForestClassifier(random_state=42)\n",
    "    baseline_rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = baseline_rf.predict(X_test)\n",
    "    \n",
    "    baseline_accuracy = accuracy_score(y_test, y_pred)\n",
    "    baseline_f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"Baseline Model Performance:\")\n",
    "    print(f\"Accuracy: {baseline_accuracy:.4f}\")\n",
    "    print(f\"F1-Score: {baseline_f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return baseline_rf, baseline_accuracy, baseline_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search(X_train, y_train):\n",
    "    \"\"\"Perform grid search for hyperparameter tuning.\"\"\"\n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=rf,\n",
    "        param_grid=param_grid,\n",
    "        scoring='f1',\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"\\nGrid Search Results:\")\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best Cross-Validation F1-Score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tuned_model(grid_search, X_test, y_test):\n",
    "    \"\"\"Evaluate the tuned model on the test set.\"\"\"\n",
    "    # Make predictions with the best model\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    tuned_accuracy = accuracy_score(y_test, y_pred)\n",
    "    tuned_f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\nTuned Model Performance:\")\n",
    "    print(f\"Accuracy: {tuned_accuracy:.4f}\")\n",
    "    print(f\"F1-Score: {tuned_f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return tuned_accuracy, tuned_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/full_processed_heart_disease_cleveland.csv\")\n",
    "\n",
    "X = df.drop([\"target\"],axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Performance:\n",
      "Accuracy: 0.8689\n",
      "F1-Score: 0.8710\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87        29\n",
      "           1       0.90      0.84      0.87        32\n",
      "\n",
      "    accuracy                           0.87        61\n",
      "   macro avg       0.87      0.87      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train baseline model\n",
    "baseline_rf, baseline_accuracy, baseline_f1 = train_baseline_model(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "\n",
      "Grid Search Results:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Best Cross-Validation F1-Score: 0.8024\n",
      "\n",
      "Tuned Model Performance:\n",
      "Accuracy: 0.9016\n",
      "F1-Score: 0.9032\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90        29\n",
      "           1       0.93      0.88      0.90        32\n",
      "\n",
      "    accuracy                           0.90        61\n",
      "   macro avg       0.90      0.90      0.90        61\n",
      "weighted avg       0.90      0.90      0.90        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "grid_search = perform_grid_search(X_train, y_train)\n",
    "    \n",
    "# Evaluate tuned model\n",
    "tuned_accuracy, tuned_f1 = evaluate_tuned_model(grid_search, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Improvement Summary:\n",
      "Accuracy Improvement: 3.28%\n",
      "F1-Score Improvement: 3.23%\n"
     ]
    }
   ],
   "source": [
    "# Print improvement summary\n",
    "print(\"\\nModel Improvement Summary:\")\n",
    "print(f\"Accuracy Improvement: {(tuned_accuracy - baseline_accuracy) * 100:.2f}%\")\n",
    "print(f\"F1-Score Improvement: {(tuned_f1 - baseline_f1) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance:\n",
      "          importance\n",
      "ca          0.122644\n",
      "cp          0.120732\n",
      "oldpeak     0.112389\n",
      "thal        0.105864\n",
      "age         0.092402\n",
      "thalach     0.092356\n",
      "chol        0.086921\n",
      "trestbps    0.075393\n",
      "slope       0.062131\n",
      "exang       0.055185\n",
      "sex         0.043103\n",
      "restecg     0.022041\n",
      "fbs         0.008839\n"
     ]
    }
   ],
   "source": [
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame(\n",
    "    grid_search.best_estimator_.feature_importances_,\n",
    "    index=[\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \n",
    "           \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\"],\n",
    "    columns=['importance']\n",
    "    ).sort_values('importance', ascending=False)\n",
    "    \n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
